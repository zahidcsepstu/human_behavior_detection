{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahidcsepstu/human_behavior_detection/blob/main/human_abnormal_behaviour_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct9Nf-VqZtFp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "ROOT_DIR = '/content/drive/MyDrive/MS_THESIS'\n",
        "\n",
        "VIDEO_DATA = ROOT_DIR + '/video_data'\n",
        "IMAGE_DATA = ROOT_DIR + '/generated_data/image_data'\n",
        "PREDICT_DATA = ROOT_DIR + '/generated_data/predict_data'\n",
        "PROCESSED_DATA = ROOT_DIR + '/generated_data/processed_data'\n",
        "TRAIN_DATA = PROCESSED_DATA + '/train'\n",
        "TEST_DATA = PROCESSED_DATA + '/test'\n",
        "DATASET_CSV = ROOT_DIR + '/dataset.csv'\n",
        "MODEL_DIR = ROOT_DIR + '/generated_data/model_data/'\n",
        "\n",
        "TEST_RATIO = 0.20\n",
        "\n",
        "MODEL_PATH = ROOT_DIR + '/generated_data/human_behaviour_detection.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw1Ze1LhIXNo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(DATASET_CSV)\n",
        "# print(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo3zBYaYIXNu"
      },
      "outputs": [],
      "source": [
        "def get_activity_class(frame, sequence):\n",
        "    frame = int(frame)\n",
        "    for x in range(len(df['sequence'])):\n",
        "        if int(df['starting_frame'][x]) <= frame <= int(df['ending_frame'][x]) and str(df['sequence'][x]) == sequence:\n",
        "            return df['activity_class'][x]\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZmhZrT8IXNv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def image_segmentation(sequence_name):\n",
        "    videoCapture = cv2.VideoCapture(VIDEO_DATA + '/' + sequence_name + '.avi')\n",
        "\n",
        "    success, image = videoCapture.read()\n",
        "    count = 0\n",
        "    while success:\n",
        "        val = int(get_activity_class(count, sequence_name))\n",
        "        if int(val) != -1:\n",
        "            st = IMAGE_DATA + '/' + str(val) + '/' + sequence_name + \"_frame_\" + str(count) + \".jpg\"\n",
        "            # print(st)\n",
        "            if not os.path.exists(IMAGE_DATA + '/' + str(val)):\n",
        "                os.makedirs(IMAGE_DATA + '/' + str(val))\n",
        "            cv2.imwrite(st, image)\n",
        "        success, image = videoCapture.read()\n",
        "        count += 1\n",
        "\n",
        "image_segmentation('seq1')\n",
        "# image_segmentation('seq2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G1M4bNoIXNw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "classes_dir = ['/0', '/1', '/2', '/3', '/4', '/5']\n",
        "\n",
        "for cls in classes_dir:\n",
        "    if not os.path.exists(TRAIN_DATA + cls):\n",
        "        os.makedirs(TRAIN_DATA + cls)\n",
        "    if not os.path.exists(TEST_DATA + cls):\n",
        "        os.makedirs(TEST_DATA + cls)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eURQxwN6IXNy"
      },
      "outputs": [],
      "source": [
        "def copy_image(folder_name):\n",
        "    all_file_names = os.listdir(IMAGE_DATA + '/' + folder_name)\n",
        "\n",
        "    np.random.shuffle(all_file_names)\n",
        "    train_file_names, test_file_names = np.split(np.array(all_file_names), [int(len(all_file_names) * (1 - TEST_RATIO))])\n",
        "\n",
        "    train_file_names = [IMAGE_DATA + '/' + folder_name + '/' + name for name in train_file_names.tolist()]\n",
        "    test_file_names = [IMAGE_DATA + '/' + folder_name + '/' + name for name in test_file_names.tolist()]\n",
        "\n",
        "    print(\"*****************************\")\n",
        "    print('Total images : ', len(all_file_names))\n",
        "    print('Training     : ', len(train_file_names))\n",
        "    print('Testing      : ', len(test_file_names))\n",
        "    print(\"*****************************\")\n",
        "\n",
        "    for name in train_file_names:\n",
        "        shutil.copy(name, TRAIN_DATA + '/' + folder_name)\n",
        "\n",
        "    for name in test_file_names:\n",
        "        shutil.copy(name, TEST_DATA + '/' + folder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9_SaIIQIXN3",
        "outputId": "8d4dc92e-7eab-41f2-e73c-f9b8f5e0d67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************\n",
            "Total images :  154\n",
            "Training     :  123\n",
            "Testing      :  31\n",
            "*****************************\n",
            "*****************************\n",
            "Total images :  144\n",
            "Training     :  115\n",
            "Testing      :  29\n",
            "*****************************\n",
            "*****************************\n",
            "Total images :  90\n",
            "Training     :  72\n",
            "Testing      :  18\n",
            "*****************************\n",
            "*****************************\n",
            "Total images :  98\n",
            "Training     :  78\n",
            "Testing      :  20\n",
            "*****************************\n",
            "*****************************\n",
            "Total images :  80\n",
            "Training     :  64\n",
            "Testing      :  16\n",
            "*****************************\n",
            "*****************************\n",
            "Total images :  83\n",
            "Training     :  66\n",
            "Testing      :  17\n",
            "*****************************\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 6):\n",
        "    copy_image(str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIFTop6DIXN4"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpfqpWB9IXN4",
        "outputId": "3c16c0d8-281e-45d8-e6fb-bb472ff8c373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 518 images belonging to 6 classes.\n",
            "Found 131 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = ImageDataGenerator().flow_from_directory(directory=TRAIN_DATA, target_size=(224, 224))\n",
        "\n",
        "test_data = ImageDataGenerator().flow_from_directory(directory=TEST_DATA, target_size=(224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ikuh7pmIXN5",
        "outputId": "f765058d-ecab-4937-c785-27e80fc8a5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg_model = VGG16(weights='imagenet', include_top=True)\n",
        "vgg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrFLLHHWIXN6"
      },
      "outputs": [],
      "source": [
        "X = vgg_model.layers[-2].output\n",
        "predictions = Dense(6, activation=\"softmax\")(X)\n",
        "model_final = Model(vgg_model.input, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQjIHPyUIXN7",
        "outputId": "b6030d2c-9905-469b-fd24-a37f2ea51661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 24582     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,285,126\n",
            "Trainable params: 134,285,126\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(learning_rate=0.0001, momentum=0.9),metrics=[\"accuracy\"])\n",
        "model_final.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UapnrWlLIXN8",
        "outputId": "1a532885-e4af-47a4-f9ad-ec4d15771798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:10 - loss: 2.4792 - accuracy: 0.1875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 168s 98s/step - loss: 2.1398 - accuracy: 0.1875 - val_loss: 1.9669 - val_accuracy: 0.3438\n",
            "Epoch 2/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:08 - loss: 1.9088 - accuracy: 0.2500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 154s 85s/step - loss: 1.8665 - accuracy: 0.2344 - val_loss: 1.4742 - val_accuracy: 0.5000\n",
            "Epoch 3/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 1.7527 - accuracy: 0.4375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 173s 106s/step - loss: 1.7091 - accuracy: 0.3906 - val_loss: 1.1998 - val_accuracy: 0.5312\n",
            "Epoch 4/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:07 - loss: 1.2365 - accuracy: 0.5625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 173s 106s/step - loss: 1.3336 - accuracy: 0.5156 - val_loss: 1.2146 - val_accuracy: 0.5625\n",
            "Epoch 5/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:08 - loss: 1.2101 - accuracy: 0.5938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 154s 85s/step - loss: 1.1691 - accuracy: 0.5469 - val_loss: 0.9179 - val_accuracy: 0.7188\n",
            "Epoch 6/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.8112 - accuracy: 0.8438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 86s/step - loss: 0.7890 - accuracy: 0.8125 - val_loss: 0.8995 - val_accuracy: 0.7188\n",
            "Epoch 7/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.9825 - accuracy: 0.5938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 86s/step - loss: 0.8170 - accuracy: 0.6719 - val_loss: 0.8187 - val_accuracy: 0.6562\n",
            "Epoch 8/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 16s - loss: 0.8119 - accuracy: 0.5000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 104s 88s/step - loss: 0.8176 - accuracy: 0.7105 - val_loss: 0.9496 - val_accuracy: 0.7188\n",
            "Epoch 9/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.9531 - accuracy: 0.6250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 153s 87s/step - loss: 0.8909 - accuracy: 0.6875 - val_loss: 0.5740 - val_accuracy: 0.9375\n",
            "Epoch 10/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.5194 - accuracy: 0.8750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 153s 87s/step - loss: 0.6451 - accuracy: 0.8281 - val_loss: 0.7199 - val_accuracy: 0.7500\n",
            "Epoch 11/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 15s - loss: 0.5381 - accuracy: 0.8333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 98s 82s/step - loss: 0.5902 - accuracy: 0.8421 - val_loss: 0.5730 - val_accuracy: 0.8750\n",
            "Epoch 12/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:07 - loss: 0.7825 - accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 159s 92s/step - loss: 0.5496 - accuracy: 0.8438 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 13/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.4802 - accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 85s/step - loss: 0.4330 - accuracy: 0.8125 - val_loss: 0.6559 - val_accuracy: 0.8125\n",
            "Epoch 14/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.5846 - accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 155s 89s/step - loss: 0.4631 - accuracy: 0.8594 - val_loss: 0.3296 - val_accuracy: 0.8438\n",
            "Epoch 15/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.2343 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 157s 91s/step - loss: 0.2019 - accuracy: 0.9531 - val_loss: 0.2817 - val_accuracy: 0.9062\n",
            "Epoch 16/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:07 - loss: 0.2668 - accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 155s 87s/step - loss: 0.2314 - accuracy: 0.9844 - val_loss: 0.3235 - val_accuracy: 0.9062\n",
            "Epoch 17/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:07 - loss: 0.2840 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 153s 85s/step - loss: 0.2587 - accuracy: 0.9531 - val_loss: 0.2913 - val_accuracy: 0.9688\n",
            "Epoch 18/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.2700 - accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 86s/step - loss: 0.2112 - accuracy: 0.9844 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
            "Epoch 19/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:10 - loss: 0.1266 - accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 153s 82s/step - loss: 0.1135 - accuracy: 0.9688 - val_loss: 0.1320 - val_accuracy: 0.9688\n",
            "Epoch 20/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 15s - loss: 0.3101 - accuracy: 0.8333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 103s 88s/step - loss: 0.1243 - accuracy: 0.9737 - val_loss: 0.1252 - val_accuracy: 0.9688\n",
            "Epoch 21/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.1255 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 153s 87s/step - loss: 0.1489 - accuracy: 0.9375 - val_loss: 0.1538 - val_accuracy: 0.9375\n",
            "Epoch 22/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.0932 - accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 87s/step - loss: 0.0955 - accuracy: 0.9531 - val_loss: 0.1431 - val_accuracy: 0.9375\n",
            "Epoch 23/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.0844 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 85s/step - loss: 0.0894 - accuracy: 0.9844 - val_loss: 0.1583 - val_accuracy: 0.9375\n",
            "Epoch 24/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:04 - loss: 0.0680 - accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 99s 34s/step - loss: 0.0820 - accuracy: 0.9474 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
            "Epoch 25/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 15s - loss: 0.1522 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 103s 87s/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9375\n",
            "Epoch 26/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.1075 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 85s/step - loss: 0.2710 - accuracy: 0.8906 - val_loss: 0.1264 - val_accuracy: 0.9375\n",
            "Epoch 27/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.0707 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 87s/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.8750\n",
            "Epoch 28/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.1558 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 152s 85s/step - loss: 0.1667 - accuracy: 0.9375 - val_loss: 0.0930 - val_accuracy: 0.9688\n",
            "Epoch 29/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.2068 - accuracy: 0.9062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 86s/step - loss: 0.1327 - accuracy: 0.9531 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
            "Epoch 30/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.0127 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 85s/step - loss: 0.0508 - accuracy: 0.9688 - val_loss: 0.0950 - val_accuracy: 0.9688\n",
            "Epoch 31/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 15s - loss: 0.1863 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 98s 83s/step - loss: 0.1182 - accuracy: 0.9737 - val_loss: 0.2001 - val_accuracy: 0.8750\n",
            "Epoch 32/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:05 - loss: 0.0242 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 86s/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.4200 - val_accuracy: 0.9062\n",
            "Epoch 33/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.3851 - accuracy: 0.9062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 157s 91s/step - loss: 0.2189 - accuracy: 0.9531 - val_loss: 0.1130 - val_accuracy: 0.9688\n",
            "Epoch 34/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:11 - loss: 0.3042 - accuracy: 0.9062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 163s 91s/step - loss: 0.1574 - accuracy: 0.9531 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 35/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.0163 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 85s/step - loss: 0.0335 - accuracy: 0.9844 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
            "Epoch 36/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:04 - loss: 0.0352 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 86s/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 37/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.0251 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 85s/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
            "Epoch 38/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:04 - loss: 0.0136 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 86s/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 39/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 1:06 - loss: 0.0287 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 151s 85s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9688\n",
            "Epoch 40/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 15s - loss: 0.1032 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 100s 85s/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"human_behaviour_detection.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=40, verbose=1, mode='auto')\n",
        "hist = model_final.fit(train_data, steps_per_epoch=2, epochs=40, validation_data=test_data,validation_steps=1, callbacks=[checkpoint, early])\n",
        "model_final.save_weights(MODEL_PATH)\n",
        "model_final.save(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY6nPFeyCKYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "55a6591c-435e-44af-8215-dffb362a9ee6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"accuracy\"])\n",
        "pyplot.plot(hist.history[\"val_accuracy\"])\n",
        "pyplot.plot(hist.history[\"loss\"])\n",
        "pyplot.plot(hist.history[\"val_loss\"])\n",
        "\n",
        "pyplot.title(\"model accuracy\")\n",
        "pyplot.xlabel(\"Epoch\")\n",
        "pyplot.ylabel(\"Accuracy\")\n",
        "pyplot.legend([\"Accuracy\", \"Validation Accuracy\", \"Loss\", \"Validation Loss\"])\n",
        "pyplot.savefig(IMAGE_DATA + '/plot.jpg', dpi = 1000)\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuMSOLAELJ-d"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(MODEL_DIR)\n",
        "model.load_weights(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.utils as image\n",
        "import numpy as np\n",
        "\n",
        "def predict_image(path):\n",
        "  imagePath = path\n",
        "  test_image = image.load_img(imagePath, target_size= (224,224))\n",
        "  test_image = image.img_to_array(test_image)\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "  result = model.predict(test_image, verbose = 0)\n",
        "  predicted_class = np.argmax(result)\n",
        "  return predicted_class"
      ],
      "metadata": {
        "id": "bH6LNOaHwiEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6hOjch_LqOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85dd6351-f8f1-4032-ac68-66b8c07ee3aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class :  4\n"
          ]
        }
      ],
      "source": [
        "predicted_class = predict_image('/content/drive/MyDrive/MS_THESIS/generated_data/processed_data/test/4/seq1_frame_772.jpg')\n",
        "print('Predicted class : ', predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def image_segmentation_pred(sequence_name):\n",
        "    videoCapture = cv2.VideoCapture(VIDEO_DATA + '/' + sequence_name + '.avi')\n",
        "\n",
        "    success, image = videoCapture.read()\n",
        "    count = 0\n",
        "    while success:\n",
        "        val = int(get_activity_class(count, sequence_name))\n",
        "        if int(val) != -1:\n",
        "            st = PREDICT_DATA + '/' + str(val) + '/' + sequence_name + \"_frame_\" + str(count) + \".jpg\"\n",
        "            # print(st)\n",
        "            if not os.path.exists(PREDICT_DATA + '/' + str(val)):\n",
        "                os.makedirs(PREDICT_DATA + '/' + str(val))\n",
        "            cv2.imwrite(st, image)\n",
        "        success, image = videoCapture.read()\n",
        "        count += 1\n",
        "\n",
        "# image_segmentation_pred('seq1')\n",
        "image_segmentation_pred('seq3')\n",
        "# image_segmentation_pred('seq4')\n",
        "# image_segmentation_pred('seq5')\n",
        "# image_segmentation_pred('seq6')"
      ],
      "metadata": {
        "id": "X20LWLmzu8Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def image_segmentation_pred(sequence_name):\n",
        "    videoCapture = cv2.VideoCapture(VIDEO_DATA + '/' + sequence_name + '.avi')\n",
        "\n",
        "    success, image = videoCapture.read()\n",
        "    count = 0\n",
        "    a_0 =0\n",
        "    a_1 =0\n",
        "    a_2 =0\n",
        "    a_3 =0\n",
        "    a_4 =0\n",
        "    a_5 =0\n",
        "\n",
        "    while success:\n",
        "        val = int(get_activity_class(count, sequence_name))\n",
        "        if int(val) != -1:\n",
        "            st = PREDICT_DATA + '/' + str(val) + '/' + sequence_name + \"_frame_\" + str(count) + \".jpg\"\n",
        "            \n",
        "            if(int(val)==0):\n",
        "              a_0+=1\n",
        "              if(a_0<12):\n",
        "                cv2.imwrite(st, image)\n",
        "            if(int(val)==1):\n",
        "              a_1+=1\n",
        "              if(a_1<12):\n",
        "                cv2.imwrite(st, image)\n",
        "            if(int(val)==2):\n",
        "              a_2+=1\n",
        "              if(a_2<12):\n",
        "                cv2.imwrite(st, image)\n",
        "            if(int(val)==3):\n",
        "              a_3+=1\n",
        "              if(a_3<12):\n",
        "                cv2.imwrite(st, image)\n",
        "            if(int(val)==4):\n",
        "              a_4+=1\n",
        "              if(a_4<12):\n",
        "                cv2.imwrite(st, image)\n",
        "            if(int(val)==5):\n",
        "              a_5+=1\n",
        "              if(a_5<12):\n",
        "                cv2.imwrite(st, image)\n",
        "        success, image = videoCapture.read()\n",
        "        count += 1\n",
        "\n",
        "# image_segmentation_pred('seq1')\n",
        "image_segmentation_pred('seq3')\n",
        "# image_segmentation_pred('seq4')\n",
        "# image_segmentation_pred('seq5')\n",
        "# image_segmentation_pred('seq6')"
      ],
      "metadata": {
        "id": "_e5eW39UIqbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def predict_all_class(activity_class):\n",
        "  directory = PREDICT_DATA + '/' + str(activity_class)\n",
        "  num_of_files = 0\n",
        "  correct_prediction = 0\n",
        "  for filename in os.listdir(directory):\n",
        "      f = os.path.join(directory, filename)\n",
        "      if os.path.isfile(f):\n",
        "        num_of_files += 1\n",
        "        # print(f)\n",
        "        r = predict_image(f)\n",
        "        # print(r)\n",
        "        if(r == activity_class):\n",
        "          correct_prediction +=1\n",
        "          \n",
        "  print(\"*****************************\")\n",
        "  print('Activity Class     : ', str(activity_class))\n",
        "  print('Total Files        : ', num_of_files)\n",
        "  print('Correct Prediction : ', correct_prediction)\n",
        "  print('Accuracy           : ', str(round(correct_prediction/num_of_files*100,2)) + ' %')\n",
        "  print(\"*****************************\")        "
      ],
      "metadata": {
        "id": "gh0wC2p5yFDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 6):\n",
        "    predict_all_class(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDcmA1aVzIZK",
        "outputId": "811390a8-40fa-4263-897e-b7fc73339a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************\n",
            "Activity Class     :  0\n",
            "Total Files        :  165\n",
            "Correct Prediction :  153\n",
            "Accuracy           :  92.73 %\n",
            "*****************************\n",
            "*****************************\n",
            "Activity Class     :  1\n",
            "Total Files        :  155\n",
            "Correct Prediction :  149\n",
            "Accuracy           :  96.13 %\n",
            "*****************************\n",
            "*****************************\n",
            "Activity Class     :  2\n",
            "Total Files        :  101\n",
            "Correct Prediction :  90\n",
            "Accuracy           :  89.11 %\n",
            "*****************************\n",
            "*****************************\n",
            "Activity Class     :  3\n",
            "Total Files        :  109\n",
            "Correct Prediction :  98\n",
            "Accuracy           :  89.91 %\n",
            "*****************************\n",
            "*****************************\n",
            "Activity Class     :  4\n",
            "Total Files        :  91\n",
            "Correct Prediction :  80\n",
            "Accuracy           :  87.91 %\n",
            "*****************************\n",
            "*****************************\n",
            "Activity Class     :  5\n",
            "Total Files        :  94\n",
            "Correct Prediction :  83\n",
            "Accuracy           :  88.3 %\n",
            "*****************************\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}